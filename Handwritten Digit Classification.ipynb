{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e674e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevent modules\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from autils import *\n",
    "%matplotlib inline\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a51b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train,y_train),(X_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f027384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAANR0lEQVR4nO3dX4xc5X3G8efxsjbBCYrX1M7GOEAJlkor1VSLqeJAqUgRQakMSoJiKakroToXsRSkXEBpq1DloiRqQqM2QnLAjVMloFQJwhckxVgoCCVyvBAX2zUthBowdr1OncgmmPWf/fViD9Vids6M55yZM97f9yONZva8c+Y8GvnxmZ13Zl9HhADMffOaDgCgPyg7kARlB5Kg7EASlB1I4rx+Hmy+F8T5WtjPQwKpvKnf6ERMeraxSmW3fZOkr0sakvRARNxbdv/ztVDX+IYqhwRQYntsaznW9ct420OSviHpo5KulLTW9pXdPh6A3qryO/sqSS9GxEsRcULSw5LW1BMLQN2qlH2ZpFdn/Ly/2PY2ttfbHrc9flKTFQ4HoIoqZZ/tTYB3fPY2IjZGxFhEjA1rQYXDAaiiStn3S1o+4+eLJR2oFgdAr1Qp+w5JV9i+zPZ8SZ+StKWeWADq1vXUW0Scsr1B0r9peuptU0TsqS0ZgFpVmmePiMckPVZTFgA9xMdlgSQoO5AEZQeSoOxAEpQdSIKyA0lQdiAJyg4kQdmBJCg7kARlB5Kg7EASlB1IgrIDSVB2IAnKDiRB2YEkKDuQBGUHkqDsQBKUHUiCsgNJUHYgCcoOJEHZgSQoO5AEZQeSoOxAEpQdSKLSKq7AIPvNJ65pOfblr9xfuu+Xbvuz0vEY391VpiZVKrvtfZKOSTot6VREjNURCkD96jiz/3FE/LKGxwHQQ/zODiRRtewh6XHbz9heP9sdbK+3PW57/KQmKx4OQLeqvoxfHREHbC+RtNX28xHx1Mw7RMRGSRsl6UKPRMXjAehSpTN7RBworickPSJpVR2hANSv67LbXmj7PW/dlnSjpHNvPgJIosrL+KWSHrH91uN8NyJ+VEuqHji+pvxFx/HFQ6XjI5t+Wmcc9MHEWOtz2Zf2/WkfkwyGrsseES9J+v0aswDoIabegCQoO5AEZQeSoOxAEpQdSCLNV1wPXFf+/9oFl/+6/AE21ZcFNZlXPl0aHzjecuyGJc+X7rvNH+oq0iDjzA4kQdmBJCg7kARlB5Kg7EASlB1IgrIDSaSZZ//bj/1r6fiX997YpySoy9Dll5SOP/9HrT8csfJnny7d9/07dnWVaZBxZgeSoOxAEpQdSIKyA0lQdiAJyg4kQdmBJNLMsw/7VNMRULPzHnij632P/+LCGpOcGzizA0lQdiAJyg4kQdmBJCg7kARlB5Kg7EASc2aeferDK0vHrz3/6f4EQd9cuvB/u953+ROna0xybmh7Zre9yfaE7d0zto3Y3mr7heJ6UW9jAqiqk5fx35J00xnb7pK0LSKukLSt+BnAAGtb9oh4StKRMzavkbS5uL1Z0i31xgJQt27foFsaEQclqbhe0uqOttfbHrc9flKTXR4OQFU9fzc+IjZGxFhEjA1rQa8PB6CFbst+yPaoJBXXE/VFAtAL3ZZ9i6R1xe11kh6tJw6AXmk7z277IUnXS7rI9n5JX5R0r6Tv2b5d0iuSPtnLkJ14+WPvKh1fMnRBn5KgLudd+oHS8U+MbOn6sd/1378qHZ+Ls/Btyx4Ra1sM3VBzFgA9xMdlgSQoO5AEZQeSoOxAEpQdSGLOfMX1vA8eq7T/m8+/t54gqM2r/7CwdHz1gqnS8QePXtx68NdHu4l0TuPMDiRB2YEkKDuQBGUHkqDsQBKUHUiCsgNJzJl59qqWjJfP2WJ2QxctLh0/9PEVLcdGbttfuu+PVzzY5ujnl47e/41bWo4tOfSTNo8993BmB5Kg7EASlB1IgrIDSVB2IAnKDiRB2YEkmGcvHB8p/3+v/JvV1Uxde1XpeAy5dPzVj7ReaefE+0+W7jtvfvkfTX782n8sHR8uj6b/Od0629+8dGvpvkemyj/7cMG88uxLt7f+GwdRuufcxJkdSIKyA0lQdiAJyg4kQdmBJCg7kARlB5KYM/Psk28Ol45PtZlZ/ee77ysd37Jh5dlG6tidix8oHZ+n8sns43Gi5diB0+Vz0f90+PrS8Y88cUfp+Ht/Pr90fPTxQy3H/HL599kP7y1fhnvpUPlnCGLHrtLxbNqe2W1vsj1he/eMbffYfs32zuJyc29jAqiqk5fx35J00yzb74uIlcXlsXpjAahb27JHxFOSjvQhC4AeqvIG3QbbzxUv8xe1upPt9bbHbY+f1GSFwwGootuy3y/pckkrJR2U9NVWd4yIjRExFhFjw2r9pQgAvdVV2SPiUEScjogpSd+UtKreWADq1lXZbY/O+PFWSbtb3RfAYGg7z277IUnXS7rI9n5JX5R0ve2Vmv5a8D5Jn+1dxM588NM/Lx3/3b/bUDq+/OrX6oxzVp6caP231SXp8A9L1hmXtHhP6/nm+T/a0ebo5XPVKzTeZv9yZbP8r935odJ9r17w09Lxh19f1kWivNqWPSLWzrK53V/vBzBg+LgskARlB5Kg7EASlB1IgrIDScyZr7i2c9lflk/jDLJRvdJ0hJ644LrDlfb/6yc/Xjq+Qj+r9PhzDWd2IAnKDiRB2YEkKDuQBGUHkqDsQBKUHUgizTw75p5LHs248HL3OLMDSVB2IAnKDiRB2YEkKDuQBGUHkqDsQBKUHUiCsgNJUHYgCcoOJEHZgSQoO5AEZQeSoOxAEnyfHQNryOXnol+tGC4df98P60xz7mt7Zre93PaTtvfa3mP788X2Edtbbb9QXC/qfVwA3erkZfwpSV+IiN+R9IeSPmf7Skl3SdoWEVdI2lb8DGBAtS17RByMiGeL28ck7ZW0TNIaSZuLu22WdEuPMgKowVm9QWf7UklXSdouaWlEHJSm/0OQtKTFPuttj9seP6nJinEBdKvjstt+t6TvS7ojIo52ul9EbIyIsYgYG9aCbjICqEFHZbc9rOmifyciflBsPmR7tBgflTTRm4gA6tDJu/GW9KCkvRHxtRlDWyStK26vk/Ro/fGQ2emYKr1onsoveJtO5tlXS/qMpF22dxbb7pZ0r6Tv2b5d0iuSPtmThABq0bbsEfG0JLcYvqHeOAB6hRc7QBKUHUiCsgNJUHYgCcoOJMFXXHHOeuPqN5qOcE7hzA4kQdmBJCg7kARlB5Kg7EASlB1IgrIDSTDPjoHV7k9J4+zwbAJJUHYgCcoOJEHZgSQoO5AEZQeSoOxAEsyzozGTT/xW6fjplVN9SpIDZ3YgCcoOJEHZgSQoO5AEZQeSoOxAEpQdSMIRUX4He7mkb0t6n6QpSRsj4uu275H0F5IOF3e9OyIeK3usCz0S15iFX4Fe2R7bdDSOzLrqcicfqjkl6QsR8azt90h6xvbWYuy+iPj7uoIC6J1O1mc/KOlgcfuY7b2SlvU6GIB6ndXv7LYvlXSVpO3Fpg22n7O9yfaiFvustz1ue/ykJqulBdC1jstu+92Svi/pjog4Kul+SZdLWqnpM/9XZ9svIjZGxFhEjA1rQfXEALrSUdltD2u66N+JiB9IUkQciojTETEl6ZuSVvUuJoCq2pbdtiU9KGlvRHxtxvbRGXe7VdLu+uMBqEsn78avlvQZSbts7yy23S1pre2VkkLSPkmf7UE+ADXp5N34pyXNNm9XOqcOYLDwCTogCcoOJEHZgSQoO5AEZQeSoOxAEpQdSIKyA0lQdiAJyg4kQdmBJCg7kARlB5Kg7EASbf+UdK0Hsw9LennGposk/bJvAc7OoGYb1FwS2bpVZ7ZLImLWtbD7WvZ3HNwej4ixxgKUGNRsg5pLIlu3+pWNl/FAEpQdSKLpsm9s+PhlBjXboOaSyNatvmRr9Hd2AP3T9JkdQJ9QdiCJRspu+ybb/2n7Rdt3NZGhFdv7bO+yvdP2eMNZNtmesL17xrYR21ttv1Bcz7rGXkPZ7rH9WvHc7bR9c0PZltt+0vZe23tsf77Y3uhzV5KrL89b339ntz0k6b8k/Ymk/ZJ2SFobEf/R1yAt2N4naSwiGv8Ahu3rJL0u6dsR8XvFtq9IOhIR9xb/US6KiDsHJNs9kl5vehnvYrWi0ZnLjEu6RdKfq8HnriTXberD89bEmX2VpBcj4qWIOCHpYUlrGsgx8CLiKUlHzti8RtLm4vZmTf9j6bsW2QZCRByMiGeL28ckvbXMeKPPXUmuvmii7MskvTrj5/0arPXeQ9Ljtp+xvb7pMLNYGhEHpel/PJKWNJznTG2X8e6nM5YZH5jnrpvlz6tqouyzLSU1SPN/qyPiDyR9VNLniper6ExHy3j3yyzLjA+Ebpc/r6qJsu+XtHzGzxdLOtBAjllFxIHiekLSIxq8pagPvbWCbnE90XCe/zdIy3jPtsy4BuC5a3L58ybKvkPSFbYvsz1f0qckbWkgxzvYXli8cSLbCyXdqMFbinqLpHXF7XWSHm0wy9sMyjLerZYZV8PPXePLn0dE3y+Sbtb0O/K/kPRXTWRokeu3Jf17cdnTdDZJD2n6Zd1JTb8iul3SYknbJL1QXI8MULZ/kbRL0nOaLtZoQ9k+rOlfDZ+TtLO43Nz0c1eSqy/PGx+XBZLgE3RAEpQdSIKyA0lQdiAJyg4kQdmBJCg7kMT/AT3d83+88ik1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# printing one train image\n",
    "plt.imshow(X_train[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "970612cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# now see the label of the above image\n",
    "print(y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f09c8256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is: (60000, 28, 28)\n",
      "The shape of y is: (60000,)\n"
     ]
    }
   ],
   "source": [
    "print ('The shape of X is: ' + str(X_train.shape))\n",
    "print ('The shape of y is: ' + str(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da40f64e",
   "metadata": {},
   "source": [
    "Now we need to reshape our data set inorder to apply for ANN model.\n",
    "\n",
    "As the ANN model receive data data in vector form so the data is converted into vector form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4192a932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the 28 by 28 image matrix into a single vector of 784 entries\n",
    "feature_vector_length = 784\n",
    "X_train = X_train.reshape(X_train.shape[0], feature_vector_length)\n",
    "X_test = X_test.reshape(X_test.shape[0], feature_vector_length)\n",
    "input_shape = (feature_vector_length,)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa0fba9",
   "metadata": {},
   "source": [
    "Now we can build the model. The model type that we will be using is Sequential.\n",
    "\n",
    "Sequential is the easiest way to build a model in Keras. \n",
    "\n",
    "It allows you to build a model layer by layer.We use the ‘add()’ function that adds layers to our neural network.\n",
    "\n",
    "Dense specifies fully connected layers.Activation Function is used for introducing non-linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "720f1bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(350, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfa9ca6",
   "metadata": {},
   "source": [
    "Now we need to specify the loss function and the optimizer, that is done by compile function available in keras.\n",
    "\n",
    "Here loss is cross entropy. Categorical cross-entropy states that we have multiple classes.\n",
    "\n",
    "The optimizer used is Adam. Metrics is used to specify how we want to judge our models performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daf7fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1332cd",
   "metadata": {},
   "source": [
    "Now training the model.\n",
    "\n",
    "model.fit function is used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28fdcb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 3ms/step - loss: 0.9978 - accuracy: 0.7760\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3268 - accuracy: 0.9202\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2066 - accuracy: 0.9484\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1634 - accuracy: 0.9596\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1335 - accuracy: 0.9662\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1126 - accuracy: 0.9709\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1107 - accuracy: 0.9727\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0947 - accuracy: 0.9773\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0857 - accuracy: 0.9787\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0827 - accuracy: 0.9801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea22ccd3a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674294cd",
   "metadata": {},
   "source": [
    "Now lets see for CNN model. \n",
    "\n",
    "All the preprocessing taks will be sames as ANN, but difference is that CNN receive data in image form(2-D) form.\n",
    "\n",
    "so data is reshaped into 2-D form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99a4d35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_width, img_height = 28, 28\n",
    "X_train = X_train.reshape(X_train.shape[0],  img_width, img_height,1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_width, img_height,1)\n",
    "input_shape = ( img_width, img_height,1,)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2850bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e535ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 55s 29ms/step - loss: 0.6288 - accuracy: 0.9189\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 61s 32ms/step - loss: 0.0956 - accuracy: 0.9708\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0771 - accuracy: 0.9768\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 58s 31ms/step - loss: 0.0661 - accuracy: 0.9802\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0581 - accuracy: 0.9824\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 58s 31ms/step - loss: 0.0548 - accuracy: 0.9843\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0508 - accuracy: 0.9847\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 58s 31ms/step - loss: 0.0497 - accuracy: 0.9858\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0474 - accuracy: 0.9865\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 58s 31ms/step - loss: 0.0445 - accuracy: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea2450ddc0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249d5285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
